import { GoogleGenAI } from "@google/genai";
import { desc, eq } from "drizzle-orm";
import type { RuntimeConfig } from "@config";
import { createDb } from "@db/client";
import { messages } from "@db/schema";
import type { AppBindings } from "@appTypes/bindings";

export async function embedAndStoreMessages(
  env: AppBindings,
  config: RuntimeConfig,
  messagesArray: { id: string; channelId: string; authorUsername: string; content: string }[],
) {
  if (messagesArray.length === 0) return;
  const ai = new GoogleGenAI({ apiKey: config.GEMINI_API_KEY });

  try {
    const vectorsToInsert = [];

    for (const msg of messagesArray) {
      if (!msg.content) continue;

      const response = await ai.models.embedContent({
        model: "text-embedding-004",
        contents: `[Membro: ${msg.authorUsername}]: ${msg.content}`,
      });

      const values = response.embeddings?.[0]?.values;
      if (values) {
        vectorsToInsert.push({
          id: msg.id,
          values,
          namespace: msg.channelId, // Namespace para isolar bancos por servidor/canal
          metadata: {
            authorUsername: msg.authorUsername,
            content: msg.content,
          },
        });
      }
    }

    if (vectorsToInsert.length > 0) {
      // Divide inserÃ§Ã£o por limites (Upsert aceita muitos, mas Ã© bom prevenir)
      const MAX_BATCH = 100;
      for (let i = 0; i < vectorsToInsert.length; i += MAX_BATCH) {
        const batch = vectorsToInsert.slice(i, i + MAX_BATCH);

        // ENV.VECTORIZE.upsert() garante que as mensagens nunca se multipliquem. 
        // Como o ID da inserÃ§Ã£o Ã© o ID oficial da mensagem do Discord (msg.id), 
        // se a mensagem jÃ¡ existir lÃ¡, o Vectorize apenas atualiza e ignora a duplicaÃ§Ã£o!
        await env.VECTORIZE.upsert(batch);
      }
      console.log(`[Vectorize] Salvos ${vectorsToInsert.length} memÃ³rias de longo prazo!`);
    }
  } catch (err) {
    console.error(`[Vectorize] Erro ao incorporar:`, err);
  }
}

export async function generateBotResponse(
  env: AppBindings,
  config: RuntimeConfig,
  userPrompt: string,
  isAskCommand: boolean = false,
  channelId?: string,
): Promise<string> {
  // 1. Inicializar o Gemini API
  const ai = new GoogleGenAI({ apiKey: config.GEMINI_API_KEY });

  // 2. Criar Embedding da Pergunta Atual para Busca (RAG)
  let vectorMatches: Array<any> = [];
  let chatContext = "Nenhum histÃ³rico passado recente com esse assunto...";

  try {
    const embeddingRes = await ai.models.embedContent({
      model: "text-embedding-004",
      contents: userPrompt,
    });

    const searchVector = embeddingRes.embeddings?.[0]?.values;

    // 3. Buscar as 10 memÃ³rias matemÃ¡ticas mais relevantes no Vectorize (filtradas pelo namespace do Canal atual)
    if (searchVector && channelId) {
      const queryResult = await env.VECTORIZE.query(searchVector, {
        topK: 10,
        namespace: channelId,
        returnMetadata: "all",
      });

      if (queryResult.matches && queryResult.matches.length > 0) {
        vectorMatches = queryResult.matches;
      }
    } else if (searchVector && config.DISCORD_CHANNEL_ID) {
      const queryResult = await env.VECTORIZE.query(searchVector, {
        topK: 10,
        namespace: config.DISCORD_CHANNEL_ID,
        returnMetadata: "all",
      });

      if (queryResult.matches && queryResult.matches.length > 0) {
        vectorMatches = queryResult.matches;
      }
    }

    if (vectorMatches.length > 0) {
      chatContext = vectorMatches
        .map((m) => `[${m.metadata?.authorUsername}]: ${m.metadata?.content}`)
        .join("\n");
    }
  } catch (err) {
    console.error("[Vectorize] Falha na busca por RAG:", err);
  }

  const systemPrompt = isAskCommand
    ? `VocÃª Ã© o "El Matadore", um membro de um grupo de amigos no Discord que acabou de ser invocado com o comando /ask para responder a uma pergunta de forma aprofundada.
Leia as MemÃ³rias Relevantes passadas (recuperadas via busca semÃ¢ntica) para entender se vocÃªs jÃ¡ debateram isso antes ou pegar contextos valiosos. DÃª uma resposta COMPLETA, PROFUNDA e TÃ‰CNICA (se for o caso), NÃƒO limite seu conhecimento ou resposta de "thinking". No entanto, aja naturalmente como membro da turma, misturando genialidade tÃ©cnica com a zoeira e o tom do grupo.
    
--- MEMÃ“RIAS RELEVANTES DO CHAT ---
${chatContext}
---------------------------------

Responda a pergunta do usuÃ¡rio a seguir com toda a sua capacidade:`
    : `VocÃª Ã© um membro engraÃ§ado de um grupo de amigos no Discord (chamado "El Matadore"). 
NÃ£o aja como um assistente de IA engessado. Abaixo estÃ£o algumas MemÃ³rias Relevantes e semelhantes do grupo que a Busca SemÃ¢ntica encontrou. DÃª uma resposta direta, sem rodeios e natural.
    
--- MEMÃ“RIAS RELEVANTES DO CHAT ---
${chatContext}
---------------------------------

Use esse contexto se fizer sentido. Agora responda a Ãºltima mensagem (onde mencionaram vocÃª)!`;

  const promptText = `${systemPrompt}\n\nNova marcaÃ§Ã£o/pergunta para vocÃª responder:\n${userPrompt}`;

  try {
    const response = await ai.models.generateContent({
      model: "gemini-3-flash-preview", // Pode usar "gemini-2.5-flash" se preferir a estabilidade
      contents: [{ role: "user", parts: [{ text: promptText }] }],
      config: isAskCommand ? {} : {},
    });

    return response.text ?? "Fiquei sem palavras! ğŸ¤";
  } catch (error) {
    console.error("Erro no Gemini:", error);
    return "Deu pane no meu sistema, rapaziada! ğŸ¤–ğŸ”¥";
  }
}
